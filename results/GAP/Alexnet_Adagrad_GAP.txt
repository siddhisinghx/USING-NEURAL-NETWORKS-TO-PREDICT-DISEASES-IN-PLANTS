Train on 43444 samples, validate on 10861 samples
Epoch 1/30
43444/43444 [==============================] - 64s 1ms/step - loss: 1.9967 - acc: 0.4558 - val_loss: 1.4430 - val_acc: 0.5788

Epoch 00001: val_loss improved from inf to 1.44299, saving model to Alexnet_GAP_Adagrad.hdf5
Epoch 2/30
43444/43444 [==============================] - 60s 1ms/step - loss: 1.0131 - acc: 0.7144 - val_loss: 0.7691 - val_acc: 0.7792

Epoch 00002: val_loss improved from 1.44299 to 0.76912, saving model to Alexnet_GAP_Adagrad.hdf5
Epoch 3/30
43444/43444 [==============================] - 61s 1ms/step - loss: 0.7457 - acc: 0.7942 - val_loss: 0.7569 - val_acc: 0.7866

Epoch 00003: val_loss improved from 0.76912 to 0.75686, saving model to Alexnet_GAP_Adagrad.hdf5
Epoch 4/30
43444/43444 [==============================] - 61s 1ms/step - loss: 0.4162 - acc: 0.8765 - val_loss: 0.5146 - val_acc: 0.8583

Epoch 00004: val_loss improved from 0.75686 to 0.51460, saving model to Alexnet_GAP_Adagrad.hdf5
Epoch 5/30
43444/43444 [==============================] - 61s 1ms/step - loss: 0.3068 - acc: 0.9070 - val_loss: 0.4141 - val_acc: 0.8756

Epoch 00005: val_loss improved from 0.51460 to 0.41411, saving model to Alexnet_GAP_Adagrad.hdf5
Epoch 6/30
43444/43444 [==============================] - 61s 1ms/step - loss: 0.2413 - acc: 0.9262 - val_loss: 0.5164 - val_acc: 0.8522

Epoch 00006: val_loss did not improve from 0.41411
Epoch 7/30
43444/43444 [==============================] - 61s 1ms/step - loss: 0.1944 - acc: 0.9404 - val_loss: 0.3396 - val_acc: 0.9077

Epoch 00007: val_loss improved from 0.41411 to 0.33962, saving model to Alexnet_GAP_Adagrad.hdf5
Epoch 8/30
43444/43444 [==============================] - 64s 1ms/step - loss: 0.1679 - acc: 0.9495 - val_loss: 0.2905 - val_acc: 0.9160

Epoch 00008: val_loss improved from 0.33962 to 0.29053, saving model to Alexnet_GAP_Adagrad.hdf5
Epoch 9/30
43444/43444 [==============================] - 70s 2ms/step - loss: 0.1371 - acc: 0.9590 - val_loss: 0.4453 - val_acc: 0.8751

Epoch 00009: val_loss did not improve from 0.29053
Epoch 10/30
43444/43444 [==============================] - 64s 1ms/step - loss: 0.1135 - acc: 0.9668 - val_loss: 0.3166 - val_acc: 0.9123

Epoch 00010: val_loss did not improve from 0.29053
Epoch 11/30
43444/43444 [==============================] - 64s 1ms/step - loss: 0.0788 - acc: 0.9796 - val_loss: 0.2644 - val_acc: 0.9283

Epoch 00011: val_loss improved from 0.29053 to 0.26439, saving model to Alexnet_GAP_Adagrad.hdf5
Epoch 12/30
43444/43444 [==============================] - 63s 1ms/step - loss: 0.0693 - acc: 0.9824 - val_loss: 0.2437 - val_acc: 0.9344

Epoch 00012: val_loss improved from 0.26439 to 0.24373, saving model to Alexnet_GAP_Adagrad.hdf5
Epoch 13/30
43444/43444 [==============================] - 63s 1ms/step - loss: 0.0632 - acc: 0.9842 - val_loss: 0.2571 - val_acc: 0.9307

Epoch 00013: val_loss did not improve from 0.24373
Epoch 14/30
43444/43444 [==============================] - 63s 1ms/step - loss: 0.0599 - acc: 0.9853 - val_loss: 0.2514 - val_acc: 0.9326

Epoch 00014: val_loss did not improve from 0.24373
Epoch 15/30
43444/43444 [==============================] - 63s 1ms/step - loss: 0.0525 - acc: 0.9880 - val_loss: 0.2202 - val_acc: 0.9412

Epoch 00015: val_loss improved from 0.24373 to 0.22021, saving model to Alexnet_GAP_Adagrad.hdf5
Epoch 16/30
43444/43444 [==============================] - 63s 1ms/step - loss: 0.0491 - acc: 0.9884 - val_loss: 0.2335 - val_acc: 0.9367

Epoch 00016: val_loss did not improve from 0.22021
Epoch 17/30
43444/43444 [==============================] - 63s 1ms/step - loss: 0.0487 - acc: 0.9885 - val_loss: 0.2307 - val_acc: 0.9371

Epoch 00017: val_loss did not improve from 0.22021
Epoch 18/30
43444/43444 [==============================] - 64s 1ms/step - loss: 0.0473 - acc: 0.9895 - val_loss: 0.2326 - val_acc: 0.9383

Epoch 00018: val_loss did not improve from 0.22021
Epoch 19/30
43444/43444 [==============================] - 64s 1ms/step - loss: 0.0476 - acc: 0.9899 - val_loss: 0.2324 - val_acc: 0.9385

Epoch 00019: val_loss did not improve from 0.22021
Epoch 20/30
43444/43444 [==============================] - 64s 1ms/step - loss: 0.0450 - acc: 0.9901 - val_loss: 0.2503 - val_acc: 0.9329

Epoch 00020: val_loss did not improve from 0.22021
